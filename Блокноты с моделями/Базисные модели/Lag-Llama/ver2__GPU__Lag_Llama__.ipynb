{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImFamWelKYjY",
        "outputId": "fac480bf-bd6c-4e41-dfd3-2fac2922b4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/weather.zip\n",
            "   creating: weather/\n",
            "  inflating: weather/weather.csv     \n",
            "Archive:  /content/exchange_rate.zip\n",
            "   creating: exchange_rate/\n",
            "  inflating: exchange_rate/.DS_Store  \n",
            "  inflating: exchange_rate/exchange_rate.csv  \n",
            "Archive:  /content/illness.zip\n",
            "   creating: illness/\n",
            "  inflating: illness/national_illness.csv  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "!git clone https://github.com/m6129/lag-llama.git -q\n",
        "# подгрузка наборов данных\n",
        "!git clone https://github.com/zhouhaoyi/ETDataset -q\n",
        "!pip install --upgrade gdown -q #https://github.com/wkentaro/gdown/issues/333\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1nXdMIJ7K201Bx3IBGNiaNFQ6FzeDEzIr/view?usp=drive_link -q\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1rN79CxW3Vldp-WDuSoG0bKq9tYQR79UK/view?usp=drive_link -q\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1WMKg7KevVEEd9jrfLG8mcpOequZMbjlM/view?usp=drive_link -q\n",
        "\n",
        "!unzip /content/weather.zip\n",
        "!unzip /content/exchange_rate.zip\n",
        "!unzip /content/illness.zip\n",
        "\n",
        "# новыt наборы данных\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1-Jy7C9Dh9QJF_yWKf2hQKUia56aQXBJ0/view?usp=drive_link -q\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1lPZhTcJVirbwhN6EpppcmpZzbDcBn4rx/view?usp=drive_link -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNY-5RgGne_F"
      },
      "source": [
        "https://github.com/time-series-foundation-models/lag-llama/issues/35\n",
        "не поддерживает ковариаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P9MGcphm2yZN"
      },
      "outputs": [],
      "source": [
        "path = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wF9C_2zL64JY"
      },
      "outputs": [],
      "source": [
        "ETTh1 = pd.read_csv(path + 'ETDataset/ETT-small/ETTh1.csv', index_col=0, parse_dates=True)\n",
        "ETTh2 = pd.read_csv(path + 'ETDataset/ETT-small/ETTh2.csv', index_col=0, parse_dates=True)\n",
        "ETTm1 = pd.read_csv(path + 'ETDataset/ETT-small/ETTm1.csv', index_col=0, parse_dates=True)\n",
        "ETTm2 = pd.read_csv(path + 'ETDataset/ETT-small/ETTm2.csv', index_col=0, parse_dates=True)\n",
        "exchange_rate = pd.read_csv(path + 'exchange_rate/exchange_rate.csv', index_col=0, parse_dates=True)\n",
        "illness = pd.read_csv(path + 'illness/national_illness.csv', index_col=0, parse_dates=True)\n",
        "weather = pd.read_csv(path + 'weather/weather.csv', index_col=0, parse_dates=True)\n",
        "de_small = pd.read_csv(path + '/de_small.csv', index_col=0, parse_dates=True)\n",
        "de_big = pd.read_csv(path + '/de_big.csv', index_col=0, parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xsn4vJ7Bq-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trim_dataset(dataset, num_rows=1440):\n",
        "    \"\"\"\n",
        "    Отрезает последние num_rows строк от датасета.\n",
        "\n",
        "    Параметры:\n",
        "    dataset (pandas.DataFrame) - исходный датасет\n",
        "    num_rows (int) - количество строк, которые нужно отрезать (по умолчанию 1440)\n",
        "\n",
        "    Возвращает:\n",
        "    pandas.DataFrame - обрезанный датасет\n",
        "    \"\"\"\n",
        "    total_rows = len(dataset)\n",
        "    start_index = total_rows - num_rows\n",
        "\n",
        "    if start_index < 0:\n",
        "        raise ValueError(\"Количество строк в датасете меньше, чем требуемое число строк для отрезания.\")\n",
        "\n",
        "    return dataset.iloc[start_index:]"
      ],
      "metadata": {
        "id": "r07hC5fCQc5T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# берём толкьо часть набора данных, последние 720 точек или 60 на просмотр и 720 или 60 на прогнозирование\n",
        "ETTh1 = trim_dataset(ETTh1, 1440)\n",
        "ETTh2 = trim_dataset(ETTh2, 1440)\n",
        "ETTm1 = trim_dataset(ETTm1, 1440)\n",
        "ETTm2 = trim_dataset(ETTm2, 1440)\n",
        "exchange_rate = trim_dataset(exchange_rate, 1440)\n",
        "weather = trim_dataset(weather, 1440)\n",
        "de_big = trim_dataset(de_big, 1440)\n",
        "de_small = trim_dataset(de_small, 120)\n",
        "illness = trim_dataset(illness, 120)"
      ],
      "metadata": {
        "id": "cu72zyAjQqgz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkuPLwIpMIzW",
        "outputId": "249044b1-b2b3-47df-87eb-853ec5c6924b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lag-llama\n"
          ]
        }
      ],
      "source": [
        "cd lag-llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "67e4fcab740d4d47b543f83a38fe312a",
            "dee7787b84cc422d88ebfad8bad57b89",
            "fe391182c0544028ab148db70cf98f50",
            "a23f672ffb9140b5b1554dda15fbdc1d",
            "ec6e4ba1552344bf883ad5fd39f612e9",
            "a23ebf4bcc2e4ac29376368e7562ec3c",
            "97620aa790c24da6be160b6183461427",
            "832c17f922024dafaea23af223307aaa",
            "cff172a8331f446cbb8cb8d3489869b7",
            "32f9f3a7924f4a0f8571829324d53019",
            "57e3e3ef26304d3ba079ff9dacf8ccab"
          ]
        },
        "id": "undw31rjAmsI",
        "outputId": "44ddf6a5-34ea-452d-cb1b-4bb7b0e54126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.1.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mConsider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "downloading https://huggingface.co/time-series-foundation-models/Lag-Llama/resolve/main/lag-llama.ckpt to /root/.cache/huggingface/hub/tmpqu2qbyxp\n",
            "lag-llama.ckpt: 100% 29.5M/29.5M [00:00<00:00, 210MB/s]\n",
            "/content/lag-llama/lag-llama.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
            "  warnings.warn(\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67e4fcab740d4d47b543f83a38fe312a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt --quiet # this could take some time # ignore the errors displayed by colab\n",
        "!huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir /content/lag-llama\n",
        "from itertools import islice\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "import torch\n",
        "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
        "from gluonts.dataset.repository.datasets import get_dataset\n",
        "\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gyH5Xq9eSvzq"
      },
      "outputs": [],
      "source": [
        "def get_lag_llama_predictions(dataset, prediction_length, device, context_length=32, use_rope_scaling=False, num_samples=100):\n",
        "    ckpt = torch.load(\"lag-llama.ckpt\", map_location=device) # Uses GPU since in this Colab we use a GPU.\n",
        "    estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "    rope_scaling_arguments = {\n",
        "        \"type\": \"linear\",\n",
        "        \"factor\": max(1.0, (context_length + prediction_length) / estimator_args[\"context_length\"]),\n",
        "    }\n",
        "\n",
        "    estimator = LagLlamaEstimator(\n",
        "        ckpt_path=\"lag-llama.ckpt\",\n",
        "        prediction_length=prediction_length,\n",
        "        context_length=context_length, # Lag-Llama was trained with a context length of 32, but can work with any context length\n",
        "\n",
        "        # estimator args\n",
        "        input_size=estimator_args[\"input_size\"],\n",
        "        n_layer=estimator_args[\"n_layer\"],\n",
        "        n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "        n_head=estimator_args[\"n_head\"],\n",
        "        scaling=estimator_args[\"scaling\"],\n",
        "        time_feat=estimator_args[\"time_feat\"],\n",
        "        rope_scaling=rope_scaling_arguments if use_rope_scaling else None,\n",
        "\n",
        "        batch_size=1,\n",
        "        num_parallel_samples=100,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    ckpt = torch.load(\"lag-llama.ckpt\", map_location=device)\n",
        "    lightning_module = estimator.create_lightning_module()\n",
        "    transformation = estimator.create_transformation()\n",
        "    predictor = estimator.create_predictor(transformation, lightning_module)\n",
        "\n",
        "    forecast_it, ts_it = make_evaluation_predictions(\n",
        "        dataset=dataset,\n",
        "        predictor=predictor,\n",
        "        num_samples=num_samples\n",
        "    )\n",
        "    forecasts = list(forecast_it)\n",
        "    tss = list(ts_it)\n",
        "\n",
        "    return forecasts, tss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "71mTY9eyHkkZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def set_seed(seed, deterministic=True):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = deterministic\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oKE6IxhCak28"
      },
      "outputs": [],
      "source": [
        "def prep_lag_func(df, target):\n",
        "  for col in df.columns:\n",
        "    # если столбец не является строковым типом\n",
        "    if df[col].dtype != 'object' and pd.api.types.is_string_dtype(df[col]) == False:\n",
        "        df[col] = df[col].astype('float32')\n",
        "  dataset = PandasDataset(df, target=target)\n",
        "  return dataset\n",
        "device = torch.device(\"cuda:0\")\n",
        "prediction_length = 96  # Определите длину прогноза.\n",
        "num_samples = 400 # количество выборок из вероятностного распределения для каждого временного интервала"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8_CwB_j7UGr"
      },
      "source": [
        "## ETTh1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZPIByxlufzN",
        "outputId": "8c8d8950-457c-4d90-a700-29abcd0baeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 18.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 0.42896103858947754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 40.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 2.6113980611165366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 35.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 4.081851641337077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 76.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 4.048158918108259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 43.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 11.186424424913195\n",
            "CPU times: user 6min 31s, sys: 1.51 s, total: 6min 32s\n",
            "Wall time: 6min 47s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTh1[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgNuacWcqwPU",
        "outputId": "d1027f6a-0792-403c-d69c-dd064a3fd835"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 32.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 24, mse: 0.24983404080073038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 33.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 96, mse: 1.6669683456420898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 33.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 192, mse: 4.634436289469401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 30.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 336, mse: 3.0204364231654575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 35.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 720, mse: 2.921006266276042\n",
            "CPU times: user 6min 44s, sys: 1.3 s, total: 6min 45s\n",
            "Wall time: 6min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTh1[['OT']], \"OT\") # провекра на одномерное прогнозирование\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Cc6XJ29QsX"
      },
      "source": [
        "## ETTh2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTh2[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685ed2aI1Dvd",
        "outputId": "d1510520-c8a6-4f45-c7f3-1a365a28062c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 29.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 31.34387715657552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 44.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 33.845497131347656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 37.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 49.315531412760414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 37.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 42.30089169456845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 50.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 127.60223524305556\n",
            "CPU times: user 6min 32s, sys: 644 ms, total: 6min 33s\n",
            "Wall time: 6min 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5_uAqsYyyh4",
        "outputId": "df7ce46a-72b4-4f95-c404-757635a07bfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 35.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 24, mse: 36.71279652913412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 33.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 96, mse: 31.20037333170573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 37.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 192, mse: 71.92296346028645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 36.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 336, mse: 22.438037690662203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 30.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 720, mse: 65.13684895833333\n",
            "CPU times: user 6min 57s, sys: 553 ms, total: 6min 58s\n",
            "Wall time: 7min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTh2[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51vbY2ku9U7H"
      },
      "source": [
        "## ETTm1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTm1[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq1HlS_z1ZcB",
        "outputId": "8fa98640-6449-4343-a80f-a0e7fa8c968e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 39.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 4.4883575439453125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 36.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 2.3384410540262857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 46.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 10.854448954264322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 39.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 26.787272135416668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 31.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 7.252789984809028\n",
            "CPU times: user 6min 41s, sys: 574 ms, total: 6min 41s\n",
            "Wall time: 6min 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvQ-LKxctJbL",
        "outputId": "33b4739a-a8d1-4e8a-f4ab-1f0e347e21cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 32.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 24, mse: 3.711392084757487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 46.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 96, mse: 1.4289960861206055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 45.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 192, mse: 6.824401219685872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 36.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 336, mse: 10.272527785528274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 40.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 720, mse: 5.618724229600694\n",
            "CPU times: user 6min 55s, sys: 606 ms, total: 6min 55s\n",
            "Wall time: 7min 4s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTm1[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN3iNwwH9YcM"
      },
      "source": [
        "## ETTm2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-voHcoY41XeM",
        "outputId": "5ef2a3e5-4c76-46c0-ab99-97251b97aa08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 43.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 15.461044311523438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 32.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 91.3369649251302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 42.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 114.84318033854167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 45.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 321.5810081845238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 44.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 70.97004123263889\n",
            "CPU times: user 6min 40s, sys: 602 ms, total: 6min 41s\n",
            "Wall time: 6min 45s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTm2[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(ETTm2[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1Z1u6yv1fac",
        "outputId": "34a7bfed-5e8a-4866-88c6-a089817efb80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 41.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 24, mse: 15.461044311523438\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 34.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 96, mse: 91.3369649251302\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 43.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 192, mse: 114.84318033854167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running evaluation: 1it [00:00, 34.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "горизонт прогнозирования: 336, mse: 321.5810081845238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 33.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 70.97004123263889\n",
            "CPU times: user 6min 39s, sys: 586 ms, total: 6min 40s\n",
            "Wall time: 6min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBgTubFh9bi7"
      },
      "source": [
        "## exchange_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrO2zf3e5ZvF",
        "outputId": "8c708c1f-ebba-432a-d41d-4440e3c4f76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 34.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 0.00033351305561761063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 53.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 0.0003654584288597107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 33.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 0.0043060338745514555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 29.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 0.09755988348098028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 46.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 0.018758069144354926\n",
            "CPU times: user 6min 38s, sys: 407 ms, total: 6min 38s\n",
            "Wall time: 6min 43s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(exchange_rate[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqNtKgls9j3c"
      },
      "source": [
        "## illness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx7wHET_uJ0a",
        "outputId": "9984657a-61b2-4ebe-fb7e-8c8ec13ad310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 35.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 81641712298.66667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 29.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 36, mse: 25933208689.77778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 67.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 48, mse: 38661701632.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 33.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 60, mse: 247903236915.2\n",
            "CPU times: user 28.8 s, sys: 117 ms, total: 28.9 s\n",
            "Wall time: 31.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 36, 48, 60]\n",
        "backtest_dataset = prep_lag_func(illness, \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## de_small"
      ],
      "metadata": {
        "id": "lPlkjbBXNifE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 36, 48, 60]\n",
        "backtest_dataset = prep_lag_func(de_small[[\"OT\"]], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amcBXzYzPTlU",
        "outputId": "7f7ae09c-828d-4fc5-c854-72c405d968ac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 21.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 578862506.6666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 32.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 36, mse: 219761934.2222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 33.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 48, mse: 170198634.66666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 28.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 60, mse: 152105028.26666668\n",
            "CPU times: user 26.7 s, sys: 159 ms, total: 26.9 s\n",
            "Wall time: 33.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## de_big"
      ],
      "metadata": {
        "id": "CLwU75kuNkf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(de_big[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlKzJJMkPe7s",
        "outputId": "96eaee19-d17f-462d-ad5e-88fa6d54a044"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 35.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 11301433.333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 34.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 4790090.666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 45.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 13412462.666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 35.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 45811818.666666664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 35.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 40783012.97777778\n",
            "CPU times: user 6min 37s, sys: 755 ms, total: 6min 37s\n",
            "Wall time: 6min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## weather"
      ],
      "metadata": {
        "id": "BTMAFLbIQeNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "set_seed(42)\n",
        "step_forecasting = [24, 96, 192, 336, 720]\n",
        "backtest_dataset = prep_lag_func(weather[['OT']], \"OT\")\n",
        "for step in step_forecasting:\n",
        "  prediction_length=step\n",
        "  forecasts, tss = get_lag_llama_predictions(backtest_dataset, prediction_length, device, num_samples) # tss временной ряд (для визуализации)\n",
        "  evaluator = Evaluator()\n",
        "  agg_metrics, ts_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "  mse = agg_metrics['MSE']\n",
        "  print(f'горизонт прогнозирования: {step}, mse: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfb43ab-f30e-4eed-c7c6-978e345cc5d0",
        "id": "8tlnAF4yQg5m"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4eb7658b6463>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = df[col].astype('float32')\n",
            "Running evaluation: 1it [00:00, 25.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 24, mse: 25.00372823079427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 31.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 96, mse: 22.632954915364582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 33.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 192, mse: 22.022178649902344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 44.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 336, mse: 112.90137881324405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 1it [00:00, 38.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "горизонт прогнозирования: 720, mse: 102.14917534722223\n",
            "CPU times: user 6min 27s, sys: 1.58 s, total: 6min 29s\n",
            "Wall time: 6min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwNx7Jaza0wh"
      },
      "source": [
        "**Стоит отметить, что наборы данных ETTh1, ETTh2, ETTm1 использовались для обучения модел**и."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67e4fcab740d4d47b543f83a38fe312a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dee7787b84cc422d88ebfad8bad57b89",
              "IPY_MODEL_fe391182c0544028ab148db70cf98f50",
              "IPY_MODEL_a23f672ffb9140b5b1554dda15fbdc1d"
            ],
            "layout": "IPY_MODEL_ec6e4ba1552344bf883ad5fd39f612e9"
          }
        },
        "dee7787b84cc422d88ebfad8bad57b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23ebf4bcc2e4ac29376368e7562ec3c",
            "placeholder": "​",
            "style": "IPY_MODEL_97620aa790c24da6be160b6183461427",
            "value": ""
          }
        },
        "fe391182c0544028ab148db70cf98f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_832c17f922024dafaea23af223307aaa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cff172a8331f446cbb8cb8d3489869b7",
            "value": 0
          }
        },
        "a23f672ffb9140b5b1554dda15fbdc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f9f3a7924f4a0f8571829324d53019",
            "placeholder": "​",
            "style": "IPY_MODEL_57e3e3ef26304d3ba079ff9dacf8ccab",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "ec6e4ba1552344bf883ad5fd39f612e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23ebf4bcc2e4ac29376368e7562ec3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97620aa790c24da6be160b6183461427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "832c17f922024dafaea23af223307aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cff172a8331f446cbb8cb8d3489869b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32f9f3a7924f4a0f8571829324d53019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e3e3ef26304d3ba079ff9dacf8ccab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}